{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76a9af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ab795e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003fc9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dcabab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1a238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa701fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14326047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27557bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638b2809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_647/3357816666.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_647/3357816666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53784a",
   "metadata": {},
   "source": [
    "실행해 보니 에러가 발생합니다. 왜 그럴까요?\n",
    "\n",
    "주의해야 할 점이 있습니다. Embedding 레이어의 인풋이 되는 문장 벡터는 그 길이가 일정해야 합니다. raw_inputs의 3개 벡터의 길이는 각각 4, 4, 5입니다.\n",
    "\n",
    "Tensorflow에서는 keras.preprocessing.sequence.pad_sequences라는 편리한 함수를 통해 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이를 일정하게 맞춰주는 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00bf7614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e0f0620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.04949879  0.02807844  0.01123594  0.04528877]\n",
      "  [-0.00212995  0.02362985  0.04472771  0.0396789 ]\n",
      "  [-0.03146434  0.03639418  0.02529032 -0.02258196]\n",
      "  [ 0.03948904 -0.0321246  -0.039543    0.04482882]\n",
      "  [-0.00152764  0.01816037  0.00187601  0.03378614]]\n",
      "\n",
      " [[ 0.04949879  0.02807844  0.01123594  0.04528877]\n",
      "  [-0.00212995  0.02362985  0.04472771  0.0396789 ]\n",
      "  [ 0.0366716   0.0165385  -0.03793801  0.01041364]\n",
      "  [ 0.04031559 -0.00578275  0.01933131  0.02178154]\n",
      "  [-0.00152764  0.01816037  0.00187601  0.03378614]]\n",
      "\n",
      " [[ 0.04949879  0.02807844  0.01123594  0.04528877]\n",
      "  [ 0.04269062  0.01492     0.00235023  0.01619664]\n",
      "  [-0.00212995  0.02362985  0.04472771  0.0396789 ]\n",
      "  [-0.03146434  0.03639418  0.02529032 -0.02258196]\n",
      "  [ 0.00038718 -0.03332315 -0.02427818  0.02656325]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_647/2532460319.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index) # 위 예시에서 딕셔너리에 포함된 단어 개수는 10개\n",
    "word_vector_dim = 4 # 그림과 같이 4차원의 워드벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim = vocab_size,\n",
    "                                     output_dim = word_vector_dim, \n",
    "                                      mask_zero = True\n",
    "                                     )\n",
    "\n",
    "# Keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야\n",
    "# Embedding 레리어의 input이 될 수 있습니다.\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                    value = word_to_index['<PAD>'],\n",
    "                                                       padding = 'post', maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54a4e3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10 # 어휘 사전의 크기. (10개의 단어)\n",
    "word_vector_dim = 4\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None, )))\n",
    "model.add(keras.layers.LSTM(8)) # 가장 널리 쓰이는 RNN인 LSTM 레이러를 사용. 이때 LSTM state벡터의 차원수는 8로 설정\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1331f626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10 # 어휘 사전의 크기 (10단어)\n",
    "word_vector_dim = 4\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None, )))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a37c7cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10 # 어휘 사전의 크기 (10개 단어)\n",
    "word_vector_dim = 4 \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None, )))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e88f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93081c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨 :  1\n",
      "1번째 리뷰의 문장 길이 :  218\n",
      "2번째 리뷰의 문장 길이 :  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0]) # 1번째 리뷰 데이터\n",
    "print(\"라벨 : \", y_train[0]) # 1번째 리뷰 데이터의 라벨\n",
    "print(\"1번째 리뷰의 문장 길이 : \", len(x_train[0]))\n",
    "print(\"2번째 리뷰의 문장 길이 : \", len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5aba0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index : word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1]) # 'the' 가 출력됩니다.\n",
    "print(word_to_index['the']) # 1이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a361321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# 실제 인코딩 인덱스는 제공된 word_to_index 기준으로 3씩 뒤로 밀려있습니다.\n",
    "word_to_index = {k:(v+3) for k, v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index['<PAD>'] = 0\n",
    "word_to_index['<BOS>'] = 1\n",
    "word_to_index['<UNK>'] = 2 #unknown\n",
    "word_to_index['<UNUSED>'] = 3\n",
    "\n",
    "index_to_word[0] = '<PAD>'\n",
    "index_to_word[1] = '<BOS>'\n",
    "index_to_word[2] = '<UNK>'\n",
    "index_to_word[3] = '<UNUSED>'\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1]) # '<BOS>' 출력\n",
    "print(word_to_index['the']) # 4가 출력\n",
    "print(index_to_word[4]) # 'the' 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "549e2fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨 :  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print(\"라벨 : \", y_train[0]) # 첫 번째 리뷰의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cab3517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 길이 평균 :  234.75892\n",
      "문장 길이 최대 :  2494\n",
      "문장 길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다.\n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "\n",
    "# 텍스트 데이터 문장길이의 리스트를 생성\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "# 문장 길이의 평균값, 최대값, 표준편차를 계산해본다.\n",
    "print(\"문장 길이 평균 : \", np.mean(num_tokens))\n",
    "print(\"문장 길이 최대 : \", np.max(num_tokens))\n",
    "print(\"문장 길이 표준편차 : \", np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,\n",
    "max_tokens = np.mean(num_tokens) + 2*np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print(\"pad_sequences maxlen : \", maxlen)\n",
    "print(\"전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다.\".format(np.sum(num_tokens<max_tokens)/len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43f96be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                    value=word_to_index['<PAD>'],\n",
    "                    padding='post', # 혹은 'pre'\n",
    "                    maxlen = maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                    value=word_to_index['<PAD>'],\n",
    "                    padding = 'post', # 혹은 'pre'\n",
    "                    maxlen = maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad54debd",
   "metadata": {},
   "source": [
    "## IMDB 영화리뷰 감성분석 - 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "800e1b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 163,761\n",
      "Trainable params: 163,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000 # 어휘 사전의 크기 (10,000개의 단어)\n",
    "word_vector_dim = 16 # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 설계. 위에서 만든 모델을 사용해봅시다.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None, )))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2cca56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]\n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2475dda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 20s 30ms/step - loss: 0.6930 - accuracy: 0.5113 - val_loss: 0.6925 - val_accuracy: 0.5033\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6871 - accuracy: 0.5715 - val_loss: 0.6836 - val_accuracy: 0.5618\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.6440 - accuracy: 0.7573 - val_loss: 0.5782 - val_accuracy: 0.7986\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.4451 - accuracy: 0.8443 - val_loss: 0.3604 - val_accuracy: 0.8515\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.2664 - accuracy: 0.8990 - val_loss: 0.3086 - val_accuracy: 0.8702\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1828 - accuracy: 0.9356 - val_loss: 0.3073 - val_accuracy: 0.8732\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1365 - accuracy: 0.9547 - val_loss: 0.3286 - val_accuracy: 0.8705\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0976 - accuracy: 0.9724 - val_loss: 0.3362 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0674 - accuracy: 0.9861 - val_loss: 0.3641 - val_accuracy: 0.8658\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0464 - accuracy: 0.9928 - val_loss: 0.3958 - val_accuracy: 0.8652\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0315 - accuracy: 0.9962 - val_loss: 0.4265 - val_accuracy: 0.8623\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0207 - accuracy: 0.9983 - val_loss: 0.4609 - val_accuracy: 0.8611\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0141 - accuracy: 0.9993 - val_loss: 0.4947 - val_accuracy: 0.8605\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0099 - accuracy: 0.9997 - val_loss: 0.5169 - val_accuracy: 0.8580\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0071 - accuracy: 0.9998 - val_loss: 0.5439 - val_accuracy: 0.8574\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.5666 - val_accuracy: 0.8576\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.5865 - val_accuracy: 0.8572\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.6063 - val_accuracy: 0.8576\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.6261 - val_accuracy: 0.8569\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6388 - val_accuracy: 0.8569\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "epochs = 20 \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs = epochs,\n",
    "                   batch_size = 512,\n",
    "                   validation_data = (x_val, y_val),\n",
    "                   verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7bf0d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.6925 - accuracy: 0.8450\n",
      "[0.6924824118614197, 0.8449599742889404]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "318bbb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f2b67f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAz70lEQVR4nO3deZxT9dX48c9hl0VEwI0dyio7IyhYhdEiiA+4C45WXIrgQuX3uGCtwIPSarVqrVREEa0OjlYtRQWxAopKRQZkX5SdAURA2Qoiw5zfH987QxiSWXNzk8l5v155Jbn35uZMCPfku4uqYowxJnmVCzoAY4wxwbJEYIwxSc4SgTHGJDlLBMYYk+QsERhjTJKzRGCMMUnOEoGJKhGZISI3RfvYIInIRhG52Ifzqoj8wns8QUQeLsqxJXifNBH5qKRxFnDeniKSFe3zmtirEHQAJngiciDkaVXgMHDUe367qqYX9Vyq2tePY8s6VR0ajfOISGNgA1BRVbO9c6cDRf43NMnHEoFBVavnPhaRjcBtqvpx/uNEpELuxcUYU3ZY1ZCJKLfoLyIPiMh3wGQRqSUi74vIThH50XtcP+Q1n4jIbd7jwSLyuYg86R27QUT6lvDYJiIyV0T2i8jHIjJeRF6PEHdRYnxERL7wzveRiNQJ2X+jiGwSkd0i8lABn083EflORMqHbLtCRJZ6j7uKyH9EZI+IbBeR50SkUoRzvSIij4Y8v897zTYRuSXfsf1E5GsR2SciW0RkTMjuud79HhE5ICLn5X62Ia/vLiILRGSvd9+9qJ9NQUSktff6PSKyQkT6h+y7VERWeufcKiL3etvreP8+e0TkBxH5TETsuhRj9oGbwpwBnAo0AobgvjOTvecNgUPAcwW8vhuwBqgD/AmYJCJSgmOnAF8BtYExwI0FvGdRYrweuBk4DagE5F6Y2gDPe+c/y3u/+oShqvOB/wKp+c47xXt8FBjh/T3nARcBdxQQN14Mfbx4fgU0B/K3T/wX+DVwCtAPGCYil3v7LvDuT1HV6qr6n3znPhX4AHjW+9ueAj4Qkdr5/oYTPptCYq4IvAd85L3ubiBdRFp6h0zCVTPWANoCs73t/wtkAXWB04HfATbvTYxZIjCFyQFGq+phVT2kqrtV9R1VPaiq+4FxwIUFvH6Tqr6oqkeBV4Ezcf/hi3ysiDQEzgFGqerPqvo5MC3SGxYxxsmq+o2qHgLeAjp6268G3lfVuap6GHjY+wwieQMYBCAiNYBLvW2o6kJV/VJVs1V1I/BCmDjCudaLb7mq/heX+EL/vk9UdZmq5qjqUu/9inJecInjW1V9zYvrDWA18D8hx0T6bApyLlAdeMz7N5oNvI/32QBHgDYicrKq/qiqi0K2nwk0UtUjqvqZ2gRoMWeJwBRmp6r+lPtERKqKyAte1ck+XFXEKaHVI/l8l/tAVQ96D6sX89izgB9CtgFsiRRwEWP8LuTxwZCYzgo9t3ch3h3pvXC//q8UkcrAlcAiVd3kxdHCq/b4zovjD7jSQWGOiwHYlO/v6yYic7yqr73A0CKeN/fcm/Jt2wTUC3ke6bMpNGZVDU2aoee9CpckN4nIpyJynrf9CWAt8JGIrBeRkUX7M0w0WSIwhcn/6+x/gZZAN1U9mWNVEZGqe6JhO3CqiFQN2daggONLE+P20HN771k70sGquhJ3wevL8dVC4KqYVgPNvTh+V5IYcNVboabgSkQNVLUmMCHkvIX9mt6GqzIL1RDYWoS4Cjtvg3z1+3nnVdUFqjoAV200FVfSQFX3q+r/qmpToD/w/0TkolLGYorJEoEprhq4Ovc9Xn3zaL/f0PuFnQmMEZFK3q/J/yngJaWJ8W3gMhE532vYHUvh/0+mAL/FJZx/5ItjH3BARFoBw4oYw1vAYBFp4yWi/PHXwJWQfhKRrrgElGsnriqraYRzTwdaiMj1IlJBRK4D2uCqcUpjPq70cL+IVBSRnrh/owzv3yxNRGqq6hHcZ5IDICKXicgvvLagvbh2lYKq4owPLBGY4noGOAnYBXwJfBij903DNbjuBh4F3sSNdwjnGUoYo6quAO7EXdy3Az/iGjMLkltHP1tVd4Vsvxd3kd4PvOjFXJQYZnh/w2xctcnsfIfcAYwVkf3AKLxf195rD+LaRL7weuKcm+/cu4HLcKWm3cD9wGX54i42Vf0Zd+Hvi/vc/wb8WlVXe4fcCGz0qsiG4v49wTWGfwwcAP4D/E1V55QmFlN8Yu0yJhGJyJvAalX1vURiTFlnJQKTEETkHBFpJiLlvO6VA3B1zcaYUrKRxSZRnAG8i2u4zQKGqerXwYZkTNlgVUPGGJPkrGrIGGOSXMJVDdWpU0cbN24cdBjGGJNQFi5cuEtV64bbl3CJoHHjxmRmZgYdhjHGJBQRyT+iPI9VDRljTJKzRGCMMUnOEoExxiQ5XxOBiPQRkTUisjbcrIIi8rSILPZu34jIHj/jMcYYcyLfGou9KX/H4xbXyAIWiMg0b7ZGAFR1RMjxdwOd/IrHGGNMeH6WCLoCa1V1vTchVQZuWoBIBuEt6BFt6enQuDGUK+fu020Zb2OMyeNnIqjH8YtrZHH84hd5RKQR0IQTZ1nM3T9ERDJFJHPnzp3FCiI9HYYMgU2bQNXdDxliycAYY3LFS2PxQOBtb4nCE6jqRFVNUdWUunXDjoeI6KGH4ODB47cdPOi2F5WVKIwxZZmfA8q2cvwqS/WJvArSQNwc8FG3eXP47Zs2wSWXQOvWx9/q1IHQpdVzSxS5ySS3RAGQlnbieY0xJtH4mQgWAM1FpAkuAQzk+JWUAPBWbqqFW5Qi6ho2dBfv/KpVg1274MUXjy8xnHrq8Ynh8ccjlygsERhjygLfEoGqZovIXcBMoDzwsqquEJGxQKaqTvMOHQhkqE/ToI4bd/wveoCqVeGFF9yFPCcHsrJg1arjb1OnwksvRT5vpJKGMcYkmoSbhjolJUWLO9dQerr7Bb95syshjBtXtF/zu3ZB27awY8eJ+xo1go0bixWGMcYERkQWqmpKuH3x0ljsq7Q0d9HOyXH3Ra3SqVMH/vxnV4IIddJJLpkYY0xZkBSJoDTS0mDiRFcCyHXxxdY+YIwpOywRFEFuiULVPf74Y9i2LeiojDEmOiwRFNPYsZCdDY88EnQkxhgTHZYIiqlpU7j9dtft9Ntvg47GGGNKzxJBCfz+91ClCjz8cNCRGGNM6VkiKIHTT4cRI+DNN2HRoqCjMcaY0rFEUEL33utGIf/ud4Ufa3MVGWPimSWCEqpZ0yWBmTNhzpzIx9nsp8aYeJcUI4v9cugQtGgB9erBf/5z/GR1uRo3Dj/XkY1MNsbEUtKPLPbLSSfBmDEwfz7861/hj4k0J5HNVWSMKY7Dh92PTz9YIiilm26Cli1dNdHRMKspNGwY/nWRthtjDLg5zqZOhfvugx494OST4a23/HkvSwSlVKGCm3do1Sp47bUT948bd+JcRVWr2lxFxphjjh6FpUthwgT49a/hF7+AM86AK66AZ591xwwfDu3a+fP+1kYQBarQrZvL4GvWuDEGoUo6+6kxpmzatw++/BLmzXO3L7+E/fvdvtNPdyWA7t3drXNnqFy59O9ZUBuBJYIomT0bLroInn4a7rkn6GiMMfFk7154/334/HN34V+2zP2ALFfO/crPveh37w5NmoTveFJalghipHdv+PprWLfO1ecZY5LXTz/BjBkwZQq8955r7D35ZDjvvGMX/a5dY3etKCgR+LlUZdL5wx/gnHPgqadcbyJjTHI5ehQ+/dRd/N9+25UETjvNjR0aNMhd+MuXDzrKE1kiiKKUFLjmGreYzR13uC+AMaZsU3VTzUyZAhkZbor66tXhyivh+utdlXGFOL/Sxnl4ieeRR+Ddd12D8F/+EnQ0xhi/fPutu/hPmQLffAMVK8Kll7qL/2WXndhbMJ5ZIoiyli3hllvg+efdxHSNGwcdkTEmWr77zv3qnzIFFixwjboXXuj6+l91FdSqFXSEJePrOAIR6SMia0RkrYiMjHDMtSKyUkRWiMgUP+OJlVGjXD3g6NFBR2KMKa29e+GVV+BXv3LTyYwY4RanevJJ1yV8zhy47bbETQLgY4lARMoD44FfAVnAAhGZpqorQ45pDjwI9FDVH0WkTNSq168Pd9/tvij33Qdt2wYdkTGmOA4fhunTj+/x07SpGw80aBC0bh10hNHlZ4mgK7BWVder6s9ABjAg3zG/Acar6o8Aqvq9j/HE1MiRrlvYQw8FHYkxpihyco79uj/9dNfYO3eu6/Hz5Zewdq1bqrasJQHwt42gHrAl5HkW0C3fMS0AROQLoDwwRlU/zH8iERkCDAFomCCT9Jx6KjzwgJuDaN4812fYGBNfVGHxYjf6PyMDtm51PX6uuMKN/k+EHj/REPRcQxWA5kBPYBDwooickv8gVZ2oqimqmlK3bt3YRlgKw4e7+UJGjnRfOGNMfFi/Hh59FNq0cVM4/OUv7j4jw00V8/e/wyWXJEcSAH9LBFuBBiHP63vbQmUB81X1CLBBRL7BJYYFPsYVM9WquYbjO+6ADz+Evn2DjsiY5PX99272zvR0V9UD8Mtfuilhrr4aatcONLxA+VkiWAA0F5EmIlIJGAhMy3fMVFxpABGpg6sqWu9jTDF3223QrBk8+KCrgzTGxM6BA/D66+5H2FlnuU4cBw/CY4+5BaPmzoXbb0/uJAA+lghUNVtE7gJm4ur/X1bVFSIyFshU1Wnevt4ishI4Ctynqrv9iikIFSu6QWbXX+8Wux80KOiIjCnbjhyBjz5yv/z/9S934W/Y0PXgS0uzXnzh2KRzMZCT4+of9+9301QnS72jMbGi6paLTU931T+7drkOG9dc4y7+PXq4mT6TmU06F7By5VwPouuvh8xMOPfcoCMypmxYtcpd/KdMgQ0b3Fog/fu7i3+fPlCpUtARJgZLBDFy8cXufvZsSwTGlMbWra53T3q6m/a9XDnXzXP0aNft06aAL74kLyzFTt260L69G7BijCmeAwdg8mR3wW/QAO69103j8vTTLjF89JFbP9ySQMlYiSCGUlPdmqSHD0dn6TljyrqlS+GFF9x64Pv3u7V8R41y1awtWgQdXdlhJYIYSk11qxbl9mE2xpzo0CF49VU3Gr9DB5g0CS6/3C3z+M03btEnSwLRZSWCGLrgAlefOXu2m7rWGHPM6tXu1/+rr8KPP7qL/VNPwa9/bf38/WYlghiqWRO6dHGJwBjjqkkzMqBnTzeZ2/jxbu3vOXNcYhgxwpJALFiJIMZSU92vnP/+101BYUwyWrcOJk6El192ff6bNHGjfW++2ZZ4DYKVCGIsNdWNfPzii6AjMSa2jhxxy7j27u0aff/8ZzfXz4cfuimeH3jAkkBQLBHEWI8ebtoJqx4yyeLAAbdIU6NGbjnHVavcvP6bN7vEcMklNuo3aFY1FGPVqkG3bpYITNm3Zw/89a/wzDPwww9uDMALL7gJ4GyalfhieTgAqamwcKFbC9WYsmbnTrcgU6NGrs9/jx6uy/THH8P//I8lgXhkiSAAqaluIrq5c4OOxJjo2brV9fJp3Ng1/F5yiZsCYto0Vwo28csSQQDOPddNjmXVQ6Ys2LgRhg1zi7v/9a9ukZeVK90soB07Bh2dKQorpAWgcmU4/3xLBCaxrVkDf/yjW/ilfHnX9fP++11CMInFSgQB6dXLzaOyc2fQkRhTPEuXwnXXuQFgb73lVv1av97No2VJIDFZIghIaqq7/+STQMMwpsi++goGDHDz/8yYASNHumqhp5+GevWCjs6UhiWCgKSkQI0aNi21iW/798OLL8I557gG388/h//7P7fe7x/+YAPAygprIwhIhQpuEjprJzDxRtWtpDdxIrzxhpsOpW1b+MtfXDtAjRpBR2iizdcSgYj0EZE1IrJWREaG2T9YRHaKyGLvdpuf8cSb1FTX4LZ1a9CRGOMGgI0fD506QdeubvnH665zawEvXQrDh1sSKKt8KxGISHlgPPArIAtYICLTVHVlvkPfVNW7/IojnvXq5e7nzIEbbgg2FpOcVGHePFf989Zbbi2ATp3g+efd4i+24ldy8LNqqCuwVlXXA4hIBjAAyJ8IklaHDlCrlqseskRgYmn3brfq14svuj7/NWq4ef9/8xs3VbpJLn4mgnrAlpDnWUC48YVXicgFwDfACFXdkv8AERkCDAFo2LChD6EGo1w5VyqwBmMTC6rw6afu4v/OO24tgG7d4KWXXBVQ9epBR2iCEnSvofeAxqraHvg38Gq4g1R1oqqmqGpK3bp1Yxqg31JTXRe8DRuCjsSUVaowdSq0auV+eEyf7n75L1ni5gC69VZLAsnOz0SwFWgQ8ry+ty2Pqu5W1cPe05eApCuU5o4nsN5Dxg/r1kG/fnDFFVCpEvz977Btm5sKon37oKMz8cLPRLAAaC4iTUSkEjAQmBZ6gIicGfK0P7DKx3jiUqtWcMYZlghMdB06BKNHw9lnu77/Tz/tJoC78UY46aSgozPxxrc2AlXNFpG7gJlAeeBlVV0hImOBTFWdBgwXkf5ANvADMNiveOKViCuuz57tivAiQUdkEt3777uunhs2uJ4/TzwBZ50VdFQmnvk6oExVpwPT820bFfL4QeBBP2NIBKmpbuDO6tVu/hZjSmLDBrjnHjftc+vW7sdFbhdlYwoSdGOx4Vg7gfUeMiVx+DA8+ii0aQOzZsGf/gSLF1sSMEVniSAONGniVnOydgJTXDNnuukfHn4YLrvMrQd8332uYdiYorJEEAdy2wnmzHErlxlTmC1b3AIwffq478/MmfCPf0CDBoW/1pj8LBHEidRUt8D30qVBR2Li2c8/w+OPu95m06fDuHGwbBn07h10ZCaRWSKIE7n1uVY9ZCKZPdtNSzJypLvwr1zpFomvXDnoyEyis0QQJ+rXhxYtrMHYnOi771w30IsuciWC99+Hf/7TLRJvTDRYIogjqaluLpjs7KAjMfHg6FE3LXSrVm5uoFGjYPlyN1LYmGiyRBBHevVyK0ItXHj89vR09+uvXDl3n54eRHQmlhYuhHPPhbvucquDLVvmVgazUcHGD5YI4kjPnu4+tJ0gPR2GDHFLA6q6+yFDLBmUVXv3usXgu3aFrCw30PCjj1y1oTF+sUQQR047Ddq1Oz4RPPQQHDx4/HEHD7rtpuxQhYwMVw00fjzccYcbaT5woE07YvxniSDOpKbCF1+40aIAmzeHPy7SdpN4vv3W9QIaNAjq1YOvvnKzg9asGXRkJllYIogzqalu5sj5893zSOvwlKH1eZLWTz/BmDFuZPBXX8Fzz7l/95SUoCMzycYSQZy54ALXKJxbPTRuHFStevwxVau67SZxffSRqwb8v/9zI4TXrIE774Ty5YOOzCQjSwRx5pRToHPnY4kgLQ0mTnRzEYm4+4kT3XaTeLZtc/X+l1ziEv6//+0a/s84I+jITDKzRBCHUlPdEoK5jcRpaW45y5wcd29JIPFkZ7t6/1at3LKRY8e66UQuvjjoyIyxRBCXUlPhyBHXaGwSm6pbH6BdO7dYTPfublDYww/b1BAmflgiiEPnnw8VKti8Q4lu/ny48EIYMODYAvIzZsAvfhF0ZMYczxJBHKpWDbp1s0SQqNauhWuvdSODv/kGJkxwpYABA2xMgIlPlgjiVGoqZGa6kaYmMezc6ap/Wrd2U0SPGeOSwu23uxKeMfHKEkGcSk11jcNz5wYdiSnMwYPwhz9As2bwt7/Bbbe5BDB6NFSvHnR0xhTO10QgIn1EZI2IrBWRkQUcd5WIqIjYUBrPuedClSo2LXU8O3oUXn4Zmjd3U35cdJGrAnr+eesOahKLb4lARMoD44G+QBtgkIi0CXNcDeC3wHy/YklEVapAjx7WThCPVF3VT8eOcOutbpT3Z5+5NQJatQo6OmOKz88SQVdgraquV9WfgQxgQJjjHgEeB37yMZaE1KsXLFkCu3YFHYnJlZnpfvn36+emiHj7bZg3z/X0MiZR+ZkI6gFbQp5nedvyiEhnoIGqflDQiURkiIhkikjmzp07ox9pnEpNdfeffBJoGAY3/ff11x9bG+Cvf3VLRV51lfUEMokvsMZiESkHPAX8b2HHqupEVU1R1ZS6dev6H1ycSElxjY1WPRSc/fvdusAtW7pxAA89BOvWuQVjKlYMOjpjosPPTm1bgQYhz+t723LVANoCn4j7SXUGME1E+qtqpo9xJYyKFd0kdJYIYu/oUZg8GX7/e9ixA264wfUMatCg8Ncak2j8LBEsAJqLSBMRqQQMBKbl7lTVvapaR1Ubq2pj4EvAkkA+qaluZspt24KOJHnMmQNdusBvfuO6hM6fD6+9ZknAlF2+JQJVzQbuAmYCq4C3VHWFiIwVkf5+vW9Z06uXu7dupP779lu4/HKXfPfscSuGff65WzbSmLLM1/GOqjodmJ5v26gIx/b0M5ZE1aED1Krlqods1lF/7NkDjzziGoArV3ZVQPfcYwvFm+RhA9/jXPnyblF7ayeIvuxseOEFNwL4hx/cmIBHHrHBYCb5FKlqSESqeb18EJEWItJfRKzPRIykprp1CDZsCDqSsmPGDGjf3vX+ad8eFi2CF1+0JGCSU1HbCOYCVUSkHvARcCPwil9BmePljiewdoLSW7EC+vSBSy91az5MnQqzZrlRwsYkq6ImAlHVg8CVwN9U9RrgbP/CMqFat4bTT7fqodL47ju3JnCHDm71tz//2SUFmxramKK3EYiInAekAbd622yZ7RgRcb2HZs9289zYhavovvsO/vQnNxHckSMwdKibHrpOnaAjMyZ+FLVEcA/wIPBPrwtoU8AqKmLo0kth+3a4+243PbUp2PbtMGIENGkCzz7rFoxfvRqee86SgDH5FalEoKqfAp9C3tQQu1R1uJ+BmePdcINb7PzJJ10Pl1degUqVgo4q/mzfDo8/7noDHTkCN97opoWw5SGNiayovYamiMjJIlINWA6sFJH7/A3NhBKBJ56Axx6DN95wA58OHgw6qvixfbvr+9+0qfvVP2iQG5E9ebIlAWMKU9SqoTaqug+4HJgBNMH1HDIx9sADMHEizJwJv/oV/Phj0BEFa9s2+O1vXRXQc8+5GULXrHELxjRrFnR0xiSGoiaCit64gcuBaap6BFDfojIF+s1v4M033dz4F17ofg0nm61b3frATZvC+PGu6uybb2DSJEsAxhRXURPBC8BGoBowV0QaAfv8CsoU7uqr4YMPYP16tyjK+vVBRxQbuQmgWTPXEyg3Abz0kksKxpjiE9WS/bAXkQrexHIxlZKSopmZNkFprq++gr59XcPxzJlulGxZsmePS3Lr1rkFeiZNclNEDx7s1glo0iTgAI1JECKyUFXDrgtfpF5DIlITGA1c4G36FBgL7I1KhKbEunZ16+X27u2qiT74ALp3DzqqosvOhqysYxf79euP3datO74NpEIFuPlmlwAaNw4sZGPKnKIOKHsZ11voWu/5jcBk3EhjE7A2beCLL1zj8cUXw7vvumkU4sm+fW5A3LffHn+x37jRJYNcFSu6i3zTpm5ZyGbN3OOmTd3j6tWD+guMKbuKVDUkIotVtWNh22LBqoYi27HDJYDly91CKgMHBhtPTg7Mneu6cL799rHurrVrH39xz33ctCnUr+9mXDXGRFepq4aAQyJyvqp+7p2wB3AoWgGa6Dj9dFeP3r+/60b5448wbFjs49i8GV591Q16W78eTj7ZDexKS3NtGDVrxj4mY0xkRU0EQ4G/e20FAD8CN/kTkimNmjXhww/huuvgjjtg1y637q7f8xMdOuRm8pw8GT7+2M2JlJoKY8fCFVdA1ar+vr8xpuSKOsXEEqCDiJzsPd8nIvcAS32MzZTQSSfBO++4hVZGjYLdu+Gpp6BclBcmVXVjGSZPdqOd9+yBRo3ce950k/XoMSZRFGuFMm90ca7/BzwT1WhM1FSs6KpmateGZ55x8xNNmuS2l9b338Prr7sEsHw5VKkCV13levT06hX9hGOM8VdplqostLJBRPoAf8FNWf2Sqj6Wb/9Q4E7gKHAAGKKqK0sRkwlRrpwrCdSuDQ8/DFu2uJ44lSq5W8WKhT8Ofb5jB/z97/D++66nT9euMGGCq4Y65ZSg/1pjTEmVJhEU2N1IRMoD44FfAVnAAhGZlu9CP0VVJ3jH9weeAuKs42NiE3FtBHXquGQwfz78/LMblFUSp53m5va5+WY425YmMqZMKDARiMh+wl/wBTipkHN3Bdaq6nrvXBnAACAvEeSraqoW4b1MFAwd6m65cnLcNM0//3zsVtjzypWhR4/oVC8ZY+JHgYlAVWuU4tz1gC0hz7OAbvkPEpE7ce0NlYDUUryfKYZy5dyFvXLloCMxxgQt8GY9VR2vqs2AB4DfhztGRIaISKaIZO7cuTO2ARpjTBnnZyLYCjQIeV7f2xZJBm6a6xOo6kRVTVHVlLp160YvQmOMMb4mggVAcxFpIiKVgIHAtNADRKR5yNN+wLc+xmOMMSaM0vQaKpCqZovIXcBMXPfRl72F78cCmao6DbhLRC4GjmCjlY0xJhC+JQIAVZ0OTM+3bVTI49/6+f7GGGMKF3hjsTHGmGBZIkgC6elujv9y5dx9enrQERlj4omvVUMmeOnpMGTIsbUANm1yz8FNC22MMVYiKOMeeuhYEsh18KDbbowxYImgzNu8uXjbjTHJxxJBGdewYfG2G2OSjyWCMm7cuBNXB6ta1W03xhiwRFDmpaXBxIlu5TARdz9xojUUG2OOsV5DSSAtzS78xpjIrERgjDFJzhKBMcYkOUsExhiT5CwRGGNMkrNEYIwxSc4SgTHGJDlLBMYYk+QsERhjTJKzRGCMMUnOEoExxiQ5SwTGGJPkfE0EItJHRNaIyFoRGRlm//8TkZUislREZolIIz/jMcYYcyLfEoGIlAfGA32BNsAgEWmT77CvgRRVbQ+8DfzJr3iMMcaE52eJoCuwVlXXq+rPQAYwIPQAVZ2jqrkLKX4J1PcxHmOMMWH4mQjqAVtCnmd52yK5FZgRboeIDBGRTBHJ3LlzZxRDNMYYExeNxSJyA5ACPBFuv6pOVNUUVU2pW7dubIMzxpgyzs9EsBVoEPK8vrftOCJyMfAQ0F9VD/sYjymh9HRo3BjKlXP36elBR2SMiSY/VyhbADQXkSa4BDAQuD70ABHpBLwA9FHV732MxZRQejoMGQIHvZacTZvcc7BVz4wpK3wrEahqNnAXMBNYBbylqitEZKyI9PcOewKoDvxDRBaLyDS/4jEl89BDx5JAroMH3XZjTNkgqhp0DMWSkpKimZmZQYeRNMqVg3BfERHIyYl9PMaYkhGRhaqaEm5fXDQWm/jVsGHxthtjEo8lAlOgceOgatXjt1Wt6rYbY8oGSwSmQGlpMHEiNGrkqoMaNXLPraHYmLLDz15DpoxIS7MLvzFlmZUIjDEmyVkiMMaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjC+s0nrjIlv1n3U+MomrTMm/lmJwPjKJq0zJv5ZIjC+2ry5eNuNMbFnicD4yiatMyb+WSIwvrJJ64yJf5YIjK9s0jpj4p/1GjK+s0nrjIlvViIwxpgkZ4nAGGOSnCUCY4xJcr4mAhHpIyJrRGStiIwMs/8CEVkkItkicrWfsRhjjAnPt0QgIuWB8UBfoA0wSETa5DtsMzAYmOJXHCbx2VxFxvjLz15DXYG1qroeQEQygAHAytwDVHWjty/HxzhMArO5iozxn5+JoB6wJeR5FtCtJCcSkSHAEICGYYakHjlyhKysLH766aeSnN4EpEqVKtSvX5+KFStGPKaguYosERgTHQkxjkBVJwITAVJSUjT//qysLGrUqEHjxo0RkZjHZ4pPVdm9ezdZWVk0adIk4nE2V5Ex/vOzsXgr0CDkeX1vW9T99NNP1K5d25JAAhERateuXWgpzuYqMsZ/fiaCBUBzEWkiIpWAgcA0v97MkkDiKcq/mc1VZIz/fEsEqpoN3AXMBFYBb6nqChEZKyL9AUTkHBHJAq4BXhCRFX7FYxKTzVVkjP98HUegqtNVtYWqNlPVcd62Uao6zXu8QFXrq2o1Va2tqmf7GU+uaHdH3L17Nx07dqRjx46cccYZ1KtXL+/5zz//XOBrMzMzGT58eKHv0b1799IF6fnkk0+47LLLonKuWElLg40bISfH3VsSMCa6EqKxOJr86I5Yu3ZtFi9eDMCYMWOoXr069957b97+7OxsKlQI/1GnpKSQkpJS6HvMmzevZMEZ0tNdL6PNm13bwrhxlkyMCZV0U0zEaunEwYMHM3ToULp168b999/PV199xXnnnUenTp3o3r07a9asAY7/hT5mzBhuueUWevbsSdOmTXn22Wfzzle9evW843v27MnVV19Nq1atSEtLQ9V1pJo+fTqtWrWiS5cuDB8+vFi//N944w3atWtH27ZteeCBBwA4evQogwcPpm3btrRr146nn34agGeffZY2bdrQvn17Bg4cWPoPy0e5iX/TJlA9lvhtUJoxxyRdiSCW3RGzsrKYN28e5cuXZ9++fXz22WdUqFCBjz/+mN/97ne88847J7xm9erVzJkzh/3799OyZUuGDRt2Qj/7r7/+mhUrVnDWWWfRo0cPvvjiC1JSUrj99tuZO3cuTZo0YdCgQUWOc9u2bTzwwAMsXLiQWrVq0bt3b6ZOnUqDBg3YunUry5cvB2DPnj0APPbYY2zYsIHKlSvnbYtXNg7BmMIlXYkglt0Rr7nmGsqXLw/A3r17ueaaa2jbti0jRoxgxYrw7eL9+vWjcuXK1KlTh9NOO40dO3accEzXrl2pX78+5cqVo2PHjmzcuJHVq1fTtGnTvD75xUkECxYsoGfPntStW5cKFSqQlpbG3Llzadq0KevXr+fuu+/mww8/5OSTTwagffv2pKWl8frrr0es8ooXNg7BmMIlXSKIZXfEatWq5T1++OGH6dWrF8uXL+e9996L2H++cuXKeY/Lly9PdnZ2iY6Jhlq1arFkyRJ69uzJhAkTuO222wD44IMPuPPOO1m0aBHnnHOOb+8fDTYOwZjCJV0iCKo74t69e6lXrx4Ar7zyStTP37JlS9avX8/GjRsBePPNN4v82q5du/Lpp5+ya9cujh49yhtvvMGFF17Irl27yMnJ4aqrruLRRx9l0aJF5OTksGXLFnr16sXjjz/O3r17OXDgQNT/nmixcQjGFC7pEgEE0x3x/vvv58EHH6RTp06+/II+6aST+Nvf/kafPn3o0qULNWrUoGbNmmGPnTVrFvXr18+7bdy4kccee4xevXrRoUMHunTpwoABA9i6dSs9e/akY8eO3HDDDfzxj3/k6NGj3HDDDbRr145OnToxfPhwTjnllKj/PdESjcRvs5+ask5ye5wkipSUFM3MzDxu26pVq2jdunVAEcWPAwcOUL16dVSVO++8k+bNmzNixIigwypQvP/b5e9uDK5EYYPaTKIRkYWqGravelKWCMqqF198kY4dO3L22Wezd+9ebr/99qBDSnix6m5sTJDiu8uHKZYRI0bEfQkg0VivI5MMrERgTAGi0evI2hhMvLNEYEwBStvryEY2m0RgicCYApS215G1MZhEYG0ExhQiLa3kPYSsjcEkAisRREGvXr2YOXPmcdueeeYZhg0bFvE1PXv2JLcb7KWXXhp2zp4xY8bw5JNPFvjeU6dOZeXKlXnPR40axccff1yM6MNLxOmq41G0RjZbO4PxkyWCKBg0aBAZGRnHbcvIyCjyfD/Tp08v8aCs/Ilg7NixXHzxxSU6l4m+aIxsjkY7gyUSU5AylwjuuQd69ozu7Z57Cn7Pq6++mg8++CBvEZqNGzeybds2fvnLXzJs2DBSUlI4++yzGT16dNjXN27cmF27dgEwbtw4WrRowfnnn583VTW4MQLnnHMOHTp04KqrruLgwYPMmzePadOmcd9999GxY0fWrVvH4MGDefvttwE3grhTp060a9eOW265hcOHD+e93+jRo+ncuTPt2rVj9erVRf58y+p01X6Jxsjm0rYzWIO1KUyZSwRBOPXUU+natSszZswAXGng2muvRUQYN24cmZmZLF26lE8//ZSlS5dGPM/ChQvJyMhg8eLFTJ8+nQULFuTtu/LKK1mwYAFLliyhdevWTJo0ie7du9O/f3+eeOIJFi9eTLNmzfKO/+mnnxg8eDBvvvkmy5YtIzs7m+effz5vf506dVi0aBHDhg0rtPopV+501bNnz2bx4sUsWLCAqVOnsnjx4rzpqpctW8bNN98MuOmqv/76a5YuXcqECROK9ZmWJaWd0qS07QzRaLAubYnCSiTxrcw1Fj/zTDDvm1s9NGDAADIyMpg0aRIAb731FhMnTiQ7O5vt27ezcuVK2rdvH/Ycn332GVdccQVVvbqE/v375+1bvnw5v//979mzZw8HDhzgkksuKTCeNWvW0KRJE1q0aAHATTfdxPjx47nHK95ceeWVAHTp0oV33323SH9j6HTVQN501Q8//HDedNX9+vWjd+/ewLHpqi+//HIuv/zyIr2HOVHDhu5XfLjtRVHaRFLaVf2isSpgaVeZs1XqCuZriUBE+ojIGhFZKyIjw+yvLCJvevvni0hjP+Px04ABA5g1axaLFi3i4MGDdOnShQ0bNvDkk08ya9Ysli5dSr9+/SJOP12YwYMH89xzz7Fs2TJGjx5d4vPkyp3KOhrTWJeF6arjWWnbGUrbYF3aEkXQVVvx0MYS9OsL41siEJHywHigL9AGGCQibfIddivwo6r+AngaeNyvePxWvXp1evXqxS233JLXSLxv3z6qVatGzZo12bFjR17VUSQXXHABU6dO5dChQ+zfv5/33nsvb9/+/fs588wzOXLkCOkh34IaNWqwf//+E87VsmVLNm7cyNq1awF47bXXuPDCC0v1N5bl6arjWWnbGUqbSEpbogi6aivRE1Es2nj8LBF0Bdaq6npV/RnIAAbkO2YA8Kr3+G3gIhERH2Py1aBBg1iyZEleIujQoQOdOnWiVatWXH/99fTo0aPA13fu3JnrrruODh060LdvX84555y8fY888gjdunWjR48etGrVKm/7wIEDeeKJJ+jUqRPr1q3L216lShUmT57MNddcQ7t27ShXrhxDhw4t1t+TTNNVx7vStDOUNpGUtkRR2tcneyKKyaBEVfXlBlwNvBTy/EbguXzHLAfqhzxfB9QJc64hQCaQ2bBhQ81v5cqVJ2wzicH+7eLf66+rVq2q6n6PulvVqm57LF7fqNHxr829NWoUm9eLhH+9SGK8PheQqRGu1wnRa0hVJ6pqiqqm5DZUGmNio7QliqCrtoJuYwn69UUSKUOU9gacB8wMef4g8GC+Y2YC53mPKwC78BbLiXTr0qXLCZnOflUmLvu3M0Xx+uvuF7yIuy9qaSIarw+6RFTa1+eigBKBn4mgArAeaAJUApYAZ+c75k5ggvd4IPBWYeeNlAhycnKK96mYwOXk5FgiMAkhyEQUjderFpwIfF2qUkQuBZ4BygMvq+o4ERnrBTRNRKoArwGdgB+Agaq6vqBzhluqcsOGDdSoUYPatWuTwG3NSUVV2b17N/v376dJkyZBh2NMmVfQUpVlYs3iI0eOkJWVVeq+9Sa2qlSpQv369alYsWLQoRhT5hWUCMrEyOKKFSvar0pjjCmhhOg1ZIwxxj+WCIwxJslZIjDGmCSXcI3FIrITCDMXY1yogxsLEa8svtKJ9/gg/mO0+EqnNPE1UtWwI3ITLhHEMxHJjNQqHw8svtKJ9/gg/mO0+ErHr/isasgYY5KcJQJjjElylgiia2LQARTC4iudeI8P4j9Gi690fInP2giMMSbJWYnAGGOSnCUCY4xJcpYIiklEGojIHBFZKSIrROS3YY7pKSJ7RWSxdxsV4xg3isgy770zw+wXEXlWRNaKyFIR6RzD2FqGfC6LRWSfiNyT75iYf34i8rKIfC8iy0O2nSoi/xaRb737WhFee5N3zLciclOMYntCRFZ7/37/FJFTIry2wO+CzzGOEZGtIf+Ol0Z4bR8RWeN9H0fGML43Q2LbKCKLI7zW188w0jUlpt+/SPNT2y3iOgtnAp29xzWAb4A2+Y7pCbwfYIwbCbPkZ8j+S4EZgADnAvMDirM88B1uoEugnx9wAdAZWB6y7U/ASO/xSODxMK87FbfuxqlALe9xrRjE1huo4D1+PFxsRfku+BzjGODeInwH1gFNObZuSZtYxJdv/5+BUUF8hpGuKbH8/lmJoJhUdbuqLvIe7wdWAfWCjarYBgB/V+dL4BQROTOAOC4C1qlq4CPFVXUubk2MUAOAV73HrwKXh3npJcC/VfUHVf0R+DfQx+/YVPUjVc32nn4J1I/mexZXhM+vKLoCa1V1var+DGTgPveoKig+cYuYXAu8Ee33LYoCrikx+/5ZIigFEWmMW1Rnfpjd54nIEhGZISJnxzYyFPhIRBaKyJAw++sBW0KeZxFMMhtI5P98QX5+uU5X1e3e4++A08McEw+f5S24El44hX0X/HaXV331coSqjXj4/H4J7FDVbyPsj9lnmO+aErPvnyWCEhKR6sA7wD2qui/f7kW46o4OwF+BqTEO73xV7Qz0Be4UkQti/P6FEpFKQH/gH2F2B/35nUBdOTzu+lqLyENANpAe4ZAgvwvPA82AjsB2XPVLPBpEwaWBmHyGBV1T/P7+WSIoARGpiPsHS1fVd/PvV9V9qnrAezwdqCgidWIVn6pu9e6/B/6JK36H2go0CHle39sWS32BRaq6I/+OoD+/EDtyq8y8++/DHBPYZykig4HLgDTvQnGCInwXfKOqO1T1qKrmAC9GeO9Av4siUgG4Engz0jGx+AwjXFNi9v2zRFBMXn3iJGCVqj4V4ZgzvOMQka64z3l3jOKrJiI1ch/jGhWX5ztsGvBrcc4F9oYUQWMl4q+wID+/fKYBub0wbgL+FeaYmUBvEanlVX309rb5SkT6APcD/VX1YIRjivJd8DPG0HanKyK89wKguYg08UqJA3Gfe6xcDKxW1axwO2PxGRZwTYnd98+vlvCyegPOxxXRlgKLvdulwFBgqHfMXcAKXA+IL4HuMYyvqfe+S7wYHvK2h8YnwHhcb41lQEqMP8NquAt7zZBtgX5+uKS0HTiCq2e9FagNzAK+BT4GTvWOTQFeCnntLcBa73ZzjGJbi6sbzv0OTvCOPQuYXtB3IYaf32ve92sp7qJ2Zv4YveeX4nrKrPMrxnDxedtfyf3ehRwb08+wgGtKzL5/NsWEMcYkOasaMsaYJGeJwBhjkpwlAmOMSXKWCIwxJslZIjDGmCRnicAYj4gcleNnRo3aTJgi0jh05ktj4kmFoAMwJo4cUtWOQQdhTKxZicCYQnjz0f/Jm5P+KxH5hbe9sYjM9iZVmyUiDb3tp4tbI2CJd+vunaq8iLzozTn/kYic5B0/3JuLfqmIZAT0Z5okZonAmGNOylc1dF3Ivr2q2g54DnjG2/ZX4FVVbY+b9O1Zb/uzwKfqJs3rjBuRCtAcGK+qZwN7gKu87SOBTt55hvrzpxkTmY0sNsYjIgdUtXqY7RuBVFVd700O9p2q1haRXbhpE45427erah0R2QnUV9XDIedojJs3vrn3/AGgoqo+KiIfAgdws6xOVW/CPWNixUoExhSNRnhcHIdDHh/lWBtdP9zcT52BBd6MmMbEjCUCY4rmupD7/3iP5+FmywRIAz7zHs8ChgGISHkRqRnppCJSDmigqnOAB4CawAmlEmP8ZL88jDnmJDl+AfMPVTW3C2ktEVmK+1U/yNt2NzBZRO4DdgI3e9t/C0wUkVtxv/yH4Wa+DKc88LqXLAR4VlX3ROnvMaZIrI3AmEJ4bQQpqror6FiM8YNVDRljTJKzEoExxiQ5KxEYY0ySs0RgjDFJzhKBMcYkOUsExhiT5CwRGGNMkvv/lR5kOblTEjYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86c57b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAs60lEQVR4nO3debyUdd3/8deHAwoHEGQxUWTREMSfsp1ccAnTCpcbbtckKhHvFNRM71uNtJQsKtM7vS3LMLcUA9MiLMxc09KUIwKegyigoCggsivrgc/vj+81h2GYmTNnme3M+/l4zGOufT7nYrg+812u72XujoiIlK4W+Q5ARETyS4lARKTEKRGIiJQ4JQIRkRKnRCAiUuKUCERESpwSgezBzJ4wswuaett8MrMlZnZKFo7rZvbZaPouM/t+Jts24HNGm9nfGxqnSDqm+wiaBzP7JG62HNgK7IjmL3H3KbmPqnCY2RLgv9z96SY+rgN93H1RU21rZr2Ad4FW7l7TJIGKpNEy3wFI03D3drHpdBc9M2upi4sUCn0fC4Oqhpo5MxtmZsvM7DtmtgK4z8z2NbO/mNkqM1sbTXeP2+d5M/uvaHqMmf3TzG6Ntn3XzE5t4La9zewFM9toZk+b2Z1m9lCKuDOJ8Ydm9q/oeH83sy5x679uZkvNbLWZXZ/m/BxtZivMrCxu2ZlmNi+aPsrMXjazdWa23Mx+aWZ7pTjW/Wb2o7j5a6J9PjSzsQnbnm5mr5vZBjN738wmxq1+IXpfZ2afmNmxsXMbt/9QM5tlZuuj96GZnpt6nudOZnZf9DesNbPpcetGmtmc6G9YbGbDo+W7VcOZ2cTYv7OZ9YqqyC4ys/eAZ6Plf4j+HdZH35HD4/ZvY2b/G/17ro++Y23M7K9m9q2Ev2eemZ2Z7G+V1JQISsP+QCegJ3Ax4d/9vmi+B7AZ+GWa/Y8G3gK6AD8D7jEza8C2DwOvAp2BicDX03xmJjF+FbgQ2A/YC7gawMz6A7+Ojn9A9HndScLdXwE+Bb6QcNyHo+kdwFXR33MscDJwaZq4iWIYHsXzRaAPkNg+8SnwDaAjcDow3sz+M1p3YvTe0d3bufvLCcfuBPwVuCP6234O/NXMOif8DXucmyTqOs8PEqoaD4+OdVsUw1HA74Bror/hRGBJis9I5vPAYcCXo/knCOdpP2A2EF+VeSswBBhK+B5fC+wEHgC+FtvIzAYABxLOjdSHu+vVzF6E/5CnRNPDgG1A6zTbDwTWxs0/T6haAhgDLIpbVw44sH99tiVcZGqA8rj1DwEPZfg3JYvxe3HzlwJ/i6ZvAKbGrWsbnYNTUhz7R8C90XR7wkW6Z4ptrwT+FDfvwGej6fuBH0XT9wI/jdvu0Phtkxz3duC2aLpXtG3LuPVjgH9G018HXk3Y/2VgTF3npj7nGehGuODum2S738TiTff9i+Ynxv6d4/62g9PE0DHapgMhUW0GBiTZrjWwltDuAiFh/Cob/6ea+0slgtKwyt23xGbMrNzMfhMVtTcQqiI6xlePJFgRm3D3TdFku3puewCwJm4ZwPupAs4wxhVx05viYjog/tju/imwOtVnEX79n2VmewNnAbPdfWkUx6FRdcmKKI4fE0oHddktBmBpwt93tJk9F1XJrAfGZXjc2LGXJixbSvg1HJPq3OymjvN8EOHfbG2SXQ8CFmcYbzK158bMyszsp1H10gZ2lSy6RK/WyT4r+k5PA75mZi2AUYQSjNSTEkFpSOwa9j9AX+Bod9+HXVURqap7msJyoJOZlcctOyjN9o2JcXn8saPP7JxqY3efT7iQnsru1UIQqpgWEH517gNc15AYCCWieA8DM4CD3L0DcFfccevqyvchoSonXg/ggwziSpTuPL9P+DfrmGS/94FDUhzzU0JpMGb/JNvE/41fBUYSqs86EEoNsRg+Brak+awHgNGEKrtNnlCNJplRIihN7QnF7XVRffON2f7A6Bd2JTDRzPYys2OB/8hSjI8CZ5jZ8VHD7k3U/V1/GPg24UL4h4Q4NgCfmFk/YHyGMTwCjDGz/lEiSoy/PeHX9paovv2rcetWEapkDk5x7JnAoWb2VTNraWZfAfoDf8kwtsQ4kp5nd19OqLv/VdSo3MrMYoniHuBCMzvZzFqY2YHR+QGYA5wfbV8BnJNBDFsJpbZyQqkrFsNOQjXbz83sgKj0cGxUeiO68O8E/heVBhpMiaA03Q60Ifza+jfwtxx97mhCg+tqQr38NMIFIJnbaWCM7l4NXEa4uC8n1CMvq2O33xMaMJ9194/jll9NuEhvBO6OYs4khieiv+FZYFH0Hu9S4CYz20ho03gkbt9NwCTgXxZ6Kx2TcOzVwBmEX/OrCY2nZyTEnanbSX+evw5sJ5SKPiK0keDurxIao28D1gP/YFcp5fuEX/BrgR+wewkrmd8RSmQfAPOjOOJdDbwBzALWADez+7Xrd8ARhDYnaQDdUCZ5Y2bTgAXunvUSiTRfZvYN4GJ3Pz7fsRQrlQgkZ8zsc2Z2SFSVMJxQLzw9z2FJEYuq3S4FJuc7lmKmRCC5tD+ha+MnhD7w49399bxGJEXLzL5MaE9ZSd3VT5KGqoZEREqcSgQiIiWu6Aad69Kli/fq1SvfYYiIFJXXXnvtY3fvmmxd0SWCXr16UVlZme8wRESKipkl3o1eS1VDIiIlTolARKTEKRGIiJQ4JQIRkRKnRCAiUuKylgjM7F4z+8jMqlKsNzO7w8wWRY+XG5ytWESkcaZMgV69oEWL8D5lSl17aP9C2r9O2XriDWE438FAVYr1pxGGuDXgGOCVTI47ZMgQFyk1Dz3k3rOnu1l4f+ih3O3/0EPu5eXusOtVXp75MbR/fvePASo91fU61YqmeBEeMJEqEfwGGBU3/xbQra5jKhFIsWmKi3g+LyQ9e+6+b+zVs6f2L4b9Ywo1EfwFOD5u/hmgIsW2FxMealLZo0eP+v31Io2Uz1/T7vm/kJgl399M+xfD/jHpEkFRNBa7+2R3r3D3iq5dk94hLZIVU6bAxRfD0qXhv9/SpWE+0zra66+HTZt2X7ZpU1ieqffeq9/ypt6/R+JDNutYrv0La/9M5DMRfMDuz3TtTsOeuSqSNY29kDf2Igz5v5BMmgTl5bsvKy8Py7V/4e+fkVRFhaZ4kb5q6HR2byx+NZNjqo1A6qsxVTuNLZY3Rf1uvtsIYsfIV2O19m/8/u7pq4aymQR+T3he7HbC82IvAsYB46L1BtwJLCY8jzRp+0DiS4lA6iPfDaVN1eOjEC4kUtzSJYKiezBNRUWFa/RRyVSvXqFeP1HPnrBkSd37x9oI4quHysth8mQYPTqzGKZMCVVJ770XqmMmTcp8X5GmYmavuXtF0nVKBNKctWgRfocnMoOdOzM7hi7k0hykSwRF9zwCkfro0SN5iaA+PS5Gj9aFX5q3oug+KqWtMbfX56THhUiRUyKQgtbYfvyjR4f6/J49Q3VQz571q98XKQVqI5CC1tjGXhEJ0rURqEQgBa0pbsgSkfSUCKSg5eL2epFSp0QgBU2NvSLZp0QgBU2NvSLZp0QgWdfYpyuNHh0ahnfuDO9KAiJNSzeUSVYlDtEQ6/4JuqCLFAqVCCSrmmI8fhHJLiUCySp1/xQpfEoEklXq/ilS+JQIJKvU/VOk8CkRSFap+6dI4VOvIck6DeMsUthUIpA6NfY+ABEpbCoRSFq6D0Ck+VOJQNLSfQAizZ8SgaSl+wBEmj8lAklL9wGINH9KBJKW7gMQaf6UCCQt3Qcg0vyp15DUSfcBiDRvKhGIiJQ4JQIRkRKnRCAiUuKUCERESpwSgYhIiVMiEBEpcVlNBGY23MzeMrNFZjYhyfqeZvaMmc0zs+fNrHs24ylVGj1URNLJWiIwszLgTuBUoD8wysz6J2x2K/A7dz8SuAn4SbbiKVWx0UOXLgX3XaOHKhmISEw2SwRHAYvc/R133wZMBUYmbNMfeDaafi7JemkkjR4qInXJZiI4EHg/bn5ZtCzeXOCsaPpMoL2ZdU48kJldbGaVZla5atWqrATbXGn0UBGpS74bi68GPm9mrwOfBz4AdiRu5O6T3b3C3Su6du2a6xiLmkYPFZG6ZDMRfAAcFDffPVpWy90/dPez3H0QcH20bF0WYyo5Gj1UROqSzUQwC+hjZr3NbC/gfGBG/AZm1sXMYjF8F7g3i/GUJI0eKiJ1ydroo+5eY2aXA08CZcC97l5tZjcBle4+AxgG/MTMHHgBuCxb8ZQyjR4qIumYu+c7hnqpqKjwysrKfIchIlJUzOw1d69Iti7fjcUiIpJnSgQiIiVOiUBEpMQpEUhG3GHLlvAuIs2LnllcgrZvhzVrYPXq5K+PP95z2Zo1UFMDrVpBp06w7767vxKXJdumTRvYsSMMcbF58+7vyZYlrtuxAw4+GPr1g7594YADQpdYEWkcJYISsGIF/N//waOPwkcfwYYNqbfde2/o3HnXq3//XdPt2oV9164NrzVrwrHffDPMr1uXPo6ysnAxb4i99w7vW7fuWtauXUgIffvuSg79+kGfPiHpiEhmlAiasYUL4dZb4YEHQing1FPhtNN2v9Anvtq2bfiv7B07YP36XYkilixi0xs3QuvW4c7mNm3Ce/x0qvfWrUMScYcPPoC33oIFC3a9//Of8PDDu+KI3TgXnyD69oVDDgnHbNly16usLLy3aKHShZQuJYJmqLISbr4ZHnsM9toLxoyBq6+Gz342u59bVhaqhDp1ys7xzaB79/A6+eTd1336aUh8iUnixRf3HH01lWQJIv7VqtWuaq/Onet+79AhJBiRQqdE0Ey4w1NPhQTw7LPhIjRhAlxxBey/f76jy762bWHgwPCKt3PnrlLEu+/Ctm2h5FJTs+cr2fL4ZVu3huqv1ath0aLwnq46zCwkjlhy6NQplEj23juUclq3Tj6dbn1ickqWsFItU1KSVJQIilxNTaj7/9nP4PXXQwPqLbeEh8/ss0++o8u/Fi3goIPCKxt27NhVBRZrgI9/j59etSr0vNq6NbzHT2/blp344rVoEX4gdOgAHTvW79WhQ/g+KZk0T0oERWrzZrjvvtAG8O67oQ78nnvCmEKxhlXJvrIy6NIlvBpj586QDBITROJ0Q0szNTXh+Bs2hHacdevCa/HiXdMbN9YdZ0NKI7HlZWXhGO7h73VPP51svkWL8IqVcJK9p1u3c2c4L6ne063buTMco1WrXVWF9X1vbDvUOefA0KGNO0YySgRFZs0auPNO+MUvwi/MY46Bn/8cRozQr7Vi1qLFriqgfNmxIySKWGJIfG3YEDodJEtEqZJR4jrY1TBvlno62ToIyaCuC3ms+i/ZNukSSVlZaFNLlUhatNj1d8TOw/btIUHHz6d637698f9Ghx+uRFDS1q+HH/wgDCH96aeh9893vgMnnKDeLtI0ysp23fMhpUWJoAg8+GCo89+yJTSK/uQnoSFYRKQpqDKhwE2ZAhddFJIAhNLAD38YlouINAUlggL3P/+zZ93ipk1w/fX5iUdEmh8lggK2fDmsXJl83Xvv5TYWEWm+lAgKVE0NjBqVuiG4R4/cxiMizZcSQYG68Ub4xz/gm98M4+3EKy+HSZPyE5eIND9KBAVo5kz48Y9DI/FvfhO6jPbsuWswtcmT9TB6EWk6enh9gXnvPRg0KAyJ8PLLGk5ZRJqGHl5fJLZtg/POC72E/vAHJQERyQ3dUFZArr0WXnklDCLXp0++oxGRUqESQYF49NHwFLFvfxvOPjvf0YhIKVEiKAALF8LYsXD00WE4aRGRXFIiyLPNm8PQsq1awSOPhNEPRURySW0EeXbFFTBvXugyqpvERCQfVCLIo9/9Dn77W7juuvBgeRGRfFAiyJOqKhg3DoYNC88ZEBHJFyWCPNi4MbQL7LMPPPxweIydiEi+6BKUY+7hITMLF8Izz0C3bvmOSERKXVZLBGY23MzeMrNFZrbHM7XMrIeZPWdmr5vZPDM7LZvxFIK77oKpU8PDZYYNy3c0IiJZTARmVgbcCZwK9AdGmVn/hM2+Bzzi7oOA84FfZSueQlBZCVdeGZ43rEdNikihqDMRmNl/mFlDEsZRwCJ3f8fdtwFTgZEJ2ziwTzTdAfiwAZ9TFNauhXPPhf33D72FWqh1RkQKRCaXo68AC83sZ2bWrx7HPhB4P25+WbQs3kTga2a2DJgJfCvZgczsYjOrNLPKVatW1SOEwvHAA7BkCUybBp075zsaEZFd6kwE7v41YBCwGLjfzF6OLsztm+DzRwH3u3t34DTgwWSlD3ef7O4V7l7RtWvXJvjY3Js3L5QGjjkm35GIiOwuowoKd98APEqo3ukGnAnMNrOkv+AjHwAHxc13j5bFuwh4JPqMl4HWQJeMIi8yVVVw+OH5jkJEZE+ZtBGMMLM/Ac8DrYCj3P1UYADwP2l2nQX0MbPeZrYXoTF4RsI27wEnR59zGCERFGfdTxo7d8L8+fD//l++IxER2VMm9xGcDdzm7i/EL3T3TWZ2Uaqd3L3GzC4HngTKgHvdvdrMbgIq3X0GIZHcbWZXERqOx3ixPTItA0uXwqefqkQgIoUpk0QwEVgemzGzNsBn3H2Juz+Tbkd3n0loBI5fdkPc9HzguPoEXIyqq8O7SgQiUogyaSP4A7Azbn5HtEwyVFUV3lUiEJFClEkiaBndBwBANK1R8+uhujo8jH6ffereVkQk1zJJBKvMbERsxsxGAh9nL6Tmp6pK1UIiUrgyaSMYB0wxs18CRrhJ7BtZjaoZ2bED3nwTTjkl35GIiCRXZyJw98XAMWbWLpr/JOtRNSOLF8PWrSoRiEjhymgYajM7HTgcaG1mALj7TVmMq9mI9RhSQ7GIFKpMbii7izDe0LcIVUPnAj2zHFezUVUFZnDYYfmOREQkuUwai4e6+zeAte7+A+BY4NDshtV8VFdD797Qtm2+IxERSS6TRLAlet9kZgcA2wnjDUkGqqqgY0fo1SsMPd2rF0yZkuegRETiZNJG8LiZdQRuAWYThoK4O5tBNRfbtsGCBaFqqKYmLFu6NDyqEmD06PzFJiISk7ZEEA0J/Yy7r3P3xwhtA/3ih4mQ1BYuDN1HY0kgZtMmuP76/MQkIpIobSJw952Ex03G5re6+/qsR9VMxIaWSOa993IXh4hIOpm0ETxjZmdbrN+oZCzWdTSZHj1yF4eISDqZJIJLCIPMbTWzDWa20cw2ZDmuZqGqCrp1g/Ly3ZeXl8OkSfmJSUQkUSaPqmzv7i3cfS933yea1/BpGaiuhqFDYfJk6NkzNBr37Bnm1VAsIoWizl5DZnZisuWJD6qR3W3ZAosWwfnnh4u+LvwiUqgy6T56Tdx0a+Ao4DXgC1mJqJlYsCA8olJjDIlIoctk0Ln/iJ83s4OA27MVUHOhh9GISLHIpLE40TJAI+fUoboaWrWCPn3yHYmISHqZtBH8gnA3MYTEMZBwh7GkUVUFffuGZCAiUsgyaSOojJuuAX7v7v/KUjzNRnU1HH10vqMQEalbJongUWCLu+8AMLMyMyt3903ZDa14ffIJvPsujB2b70hEROqW0Z3FQJu4+TbA09kJp3l4883wrh5DIlIMMkkEreMfTxlNl6fZvuSpx5CIFJNMEsGnZjY4NmNmQ4DN2Qup+FVXQ+vWcPDB+Y5ERKRumbQRXAn8wcw+JDyqcn/Coyslhaqq8GjKsrJ8RyIiUrdMbiibZWb9gL7RorfcfXt2wypu1dVw0kn5jkJEJDOZPLz+MqCtu1e5exXQzswuzX5oxWndOli2TO0DIlI8Mmkj+Ka7r4vNuPta4JtZi6jIzZ8f3tVjSESKRSaJoCz+oTRmVgbslb2Qipt6DIlIsckkEfwNmGZmJ5vZycDvgScyObiZDTezt8xskZlNSLL+NjObE73eNrN19Yq+AFVXQ7t2egKZiBSPTHoNfQe4GBgXzc8j9BxKKyo53Al8kTBQ3Swzm+Hu82PbuPtVcdt/CxiUeeiFqaoK+veHFg0Zzk9EJA8yeULZTuAVYAnhWQRfAN7M4NhHAYvc/R133wZMBUam2X4UobRR1Kqr1T4gIsUlZYnAzA4lXJxHAR8D0wDcPdOOkQcC78fNLwOSDsNmZj2B3sCzGR67IH38MaxcqUQgIsUlXdXQAuBF4Ax3XwRgZlel2b4xzgcejQ1sl8jMLiZUT9GjgCvfq6vDuxqKRaSYpKsaOgtYDjxnZndHDcWWZvtEHwAHxc13j5Ylcz5pqoXcfbK7V7h7RdeuXesRQm7FegypRCAixSRlInD36e5+PtAPeI4w1MR+ZvZrM/tSBseeBfQxs95mthfhYj8jcaPoruV9gZcbEH9Bqa6Gjh2hW7d8RyIikrlMGos/dfeHo2cXdwdeJ/Qkqmu/GuBy4ElC4/Ij7l5tZjeZ2Yi4Tc8Hprq7JztOMamqCqUBq0+5SUQkz6zYrr8VFRVeWVlZ94Y55g6dO8N558Fdd+U7GhGR3ZnZa+5ekWyders3kRUrYO1atQ+ISPFRImgiGlpCRIqVEkETiXUdVYlARIqNEkETqaqCrl3DS0SkmCgRNBENLSEixUqJoAm4h0Sg9gERKUZKBE3g/fdh40aVCESkOCkRNAH1GBKRYqZE0AQ02JyIFDMlgiZQVQUHHAD77pvvSERE6k+JoAmox5CIFDMlgkbauRPmz1e1kIgULyWCRnr3Xdi8WSUCESleSgSNpB5DIlLslAgaKdZjqH///MYhItJQSgSNVFUFPXtC+/b5jkREpGGUCBpJPYZEpNgpETRCTQ0sWKD2AREpbkoEjbBoEWzbphKBiBQ3JYJGUI8hEWkOlAgaoboazOCww/IdiYhIwykRNEJVFRxyCLRpk+9IREQaTomgEdRjSESaAyWCBtq6Fd5+W+0DIlL8lAga6O23YccOlQhEpPgpETSQegyJSHOhRNBA1dXQsiX07ZvvSEREGkeJoIGqquDQQ2GvvfIdiYhI4ygRNFBVlaqFRKR5UCJogE2b4J131FAsIs2DEkEDvPkmuKtEICLNQ1YTgZkNN7O3zGyRmU1Isc15ZjbfzKrN7OFsxtNUYg+jUYlARJqDltk6sJmVAXcCXwSWAbPMbIa7z4/bpg/wXeA4d19rZvtlK56mVFUVGokPOSTfkYiINF42SwRHAYvc/R133wZMBUYmbPNN4E53Xwvg7h9lMZ4mU10dBpprmbU0KiKSO9lMBAcC78fNL4uWxTsUONTM/mVm/zaz4ckOZGYXm1mlmVWuWrUqS+FmTj2GRKQ5yXdjcUugDzAMGAXcbWYdEzdy98nuXuHuFV27ds1thAk2bID33lP7gIg0H9lMBB8AB8XNd4+WxVsGzHD37e7+LvA2ITEUrPlRC4dKBCLSXGQzEcwC+phZbzPbCzgfmJGwzXRCaQAz60KoKnonizE1mnoMiUhzk7VE4O41wOXAk8CbwCPuXm1mN5nZiGizJ4HVZjYfeA64xt1XZyumplBVBeXl0KtXviMREWkaWe334u4zgZkJy26Im3bgv6NXUaiuhv79oUW+W1dERJqILmf1pB5DItLcKBHUw5o1sHy52gdEpHlRIqiHWEOxSgQi0pwoEWRgypTQOHziiWF+4cK8hiMi0qQ0SEIdpkyBiy8OQ0/HTJgAnTvD6NH5i0tEpKlY6LhTPCoqKryysjJnn9erFyxduufynj1hyZKchSFSELZv386yZcvYsmVLvkORFFq3bk337t1p1arVbsvN7DV3r0i2j0oEdXjvvfotF2nOli1bRvv27enVqxdmlu9wJIG7s3r1apYtW0bv3r0z3k9tBHXo0aN+y0Wasy1bttC5c2clgQJlZnTu3LneJTYlgjpMmhTuJI5XXh6Wi5QiJYHC1pB/HyWCOoweDZMnwz77hPnu3cO8GopFpLlQIshAnz7w6afwjW/A++8rCYhkKtb1ukWL8D5lSuOOt3r1agYOHMjAgQPZf//9OfDAA2vnt23blnbfyspKrrjiijo/Y+jQoY0Lsgip11AdNm2CQYNg82Z44w3o0CFnHy1ScN58800OO+ywjLZN1vW6vLzpStQTJ06kXbt2XH311bXLampqaKlHByb9d0rXa0glgjpMmABvvw33368kIFIf11+/exKAMH/99U37OWPGjGHcuHEcffTRXHvttbz66qsce+yxDBo0iKFDh/LWW28B8Pzzz3PGGWcAIYmMHTuWYcOGcfDBB3PHHXfUHq9du3a12w8bNoxzzjmHfv36MXr0aGI/nGfOnEm/fv0YMmQIV1xxRe1x4y1ZsoQTTjiBwYMHM3jwYF566aXadTfffDNHHHEEAwYMYMKECQAsWrSIU045hQEDBjB48GAWL17ctCcqDaXONJ5+Gn7xC7jySvjCF/IdjUhxyWXX62XLlvHSSy9RVlbGhg0bePHFF2nZsiVPP/001113HY899tge+yxYsIDnnnuOjRs30rdvX8aPH79H3/vXX3+d6upqDjjgAI477jj+9a9/UVFRwSWXXMILL7xA7969GTVqVNKY9ttvP5566ilat27NwoULGTVqFJWVlTzxxBP8+c9/5pVXXqG8vJw1a9YAMHr0aCZMmMCZZ57Jli1b2LlzZ9OfqBSUCFJYtw4uvBD69YMf/zjf0YgUnx49kt+MmY2u1+eeey5lZWUArF+/ngsuuICFCxdiZmzfvj3pPqeffjp77703e++9N/vttx8rV66ke/fuu21z1FFH1S4bOHAgS5YsoV27dhx88MG1/fRHjRrF5MmT9zj+9u3bufzyy5kzZw5lZWW8/fbbADz99NNceOGFlEfdETt16sTGjRv54IMPOPPMM4FwU1guqWoohSuuCCONPvggtGmT72hEik8uu163bdu2dvr73/8+J510ElVVVTz++OMp+9TvvffetdNlZWXU1NQ0aJtUbrvtNj7zmc8wd+5cKisr62zMziclgiQeeywkgO9/HyqSNq2ISF1iXa979gSz8J6Lrtfr16/nwAMPBOD+++9v8uP37duXd955hyXRGDPTpk1LGUe3bt1o0aIFDz74IDt27ADgi1/8Ivfddx+bogaUNWvW0L59e7p378706dMB2Lp1a+36XFAiSLBiBVxySUgA112X72hEitvo0WFMrp07w3suul5fe+21fPe732XQoEH1+gWfqTZt2vCrX/2K4cOHM2TIENq3b0+HJD1JLr30Uh544AEGDBjAggULakstw4cPZ8SIEVRUVDBw4EBuvfVWAB588EHuuOMOjjzySIYOHcqKFSuaPPZU1H00jjuMGBEaiWfPhgx7yYmUjPp0H23OPvnkE9q1a4e7c9lll9GnTx+uuuqqfIdVS91HG+Hee+Evf4Gf/lRJQERSu/vuuxk4cCCHH34469ev55JLLsl3SI2iXkORd9/d1U30W9/KdzQiUsiuuuqqgioBNJZKBMCOHXDBBeE2+PvuC+8iIqVCJQLgttvgxRfhgQc0vLSIlJ6S/+1bVRVueT/zTPj61/MdjYhI7pV0Iti2LVz8O3aE3/wm9HUWESk1JZ0IbroJ5swJN7l07ZrvaESkLieddBJPPvnkbstuv/12xo8fn3KfYcOGEetyftppp7Fu3bo9tpk4cWJtf/5Upk+fzvz582vnb7jhBp5++ul6RF+4SjYR/Pvf8JOfhPGERo7MdzQikolRo0YxderU3ZZNnTo15cBviWbOnEnHjh0b9NmJieCmm27ilFNOadCxCk1JJILEh2Pcc094yMxBB8Htt+c5OJEideWVMGxY076uvDL9Z55zzjn89a9/rR23Z8mSJXz44YeccMIJjB8/noqKCg4//HBuvPHGpPv36tWLjz/+GIBJkyZx6KGHcvzxx9cOVQ3hHoHPfe5zDBgwgLPPPptNmzbx0ksvMWPGDK655hoGDhzI4sWLGTNmDI8++igAzzzzDIMGDeKII45g7NixbN26tfbzbrzxRgYPHswRRxzBggUL9oipEIarbvaJIPZwjKVLw53DS5fCuHGwaFHoJRR7BKWIFL5OnTpx1FFH8cQTTwChNHDeeedhZkyaNInKykrmzZvHP/7xD+bNm5fyOK+99hpTp05lzpw5zJw5k1mzZtWuO+uss5g1axZz587lsMMO45577mHo0KGMGDGCW265hTlz5nDIIYfUbr9lyxbGjBnDtGnTeOONN6ipqeHXv/517fouXbowe/Zsxo8fn7T6KTZc9ezZs5k2bVrtU9Tih6ueO3cu1157LRCGq77sssuYO3cuL730Et26dWvcSaUEuo8mezhGTQ20bw+f/3x+YhJpDvJVmo5VD40cOZKpU6dyzz33APDII48wefJkampqWL58OfPnz+fII49MeowXX3yRM888s3Yo6BEjRtSuq6qq4nvf+x7r1q3jk08+4ctf/nLaeN566y169+7NoYceCsAFF1zAnXfeyZVR8eass84CYMiQIfzxj3/cY/9CGK662SeCVA/B2Lgxt3GISNMYOXIkV111FbNnz2bTpk0MGTKEd999l1tvvZVZs2ax7777MmbMmJTDT9dlzJgxTJ8+nQEDBnD//ffz/PPPNyre2FDWqYaxjh+ueufOnTl/FgFkuWrIzIab2VtmtsjMJiRZP8bMVpnZnOj1X00dQ6obxHr2bOpPEpFcaNeuHSeddBJjx46tbSTesGEDbdu2pUOHDqxcubK26iiVE088kenTp7N582Y2btzI448/Xrtu48aNdOvWje3btzNlypTa5e3bt2djkl+Qffv2ZcmSJSxatAgIo4h+vh7VDYUwXHXWEoGZlQF3AqcC/YFRZtY/yabT3H1g9PptU8eRy4djiEhujBo1irlz59YmggEDBjBo0CD69evHV7/6VY477ri0+w8ePJivfOUrDBgwgFNPPZXPfe5ztet++MMfcvTRR3PcccfRr1+/2uXnn38+t9xyC4MGDdqtgbZ169bcd999nHvuuRxxxBG0aNGCcePGZfy3FMJw1VkbhtrMjgUmuvuXo/nvArj7T+K2GQNUuPvlmR63IcNQT5kC//3f8NFHoYTw4x/nZlx0keZGw1AXh0IahvpA4P24+WXRskRnm9k8M3vUzA5KdiAzu9jMKs2sctWqVfUOZPRoWLlyV68hJQERkV3y3X30caCXux8JPAU8kGwjd5/s7hXuXtFVtwCLiDSpbCaCD4D4X/jdo2W13H21u2+NZn8LDMliPCLSBIrtqYalpiH/PtlMBLOAPmbW28z2As4HZsRvYGbxd0KMAN7MYjwi0kitW7dm9erVSgYFyt1ZvXp1vbugZu0+AnevMbPLgSeBMuBed682s5uASnefAVxhZiOAGmANMCZb8YhI43Xv3p1ly5bRkLY6yY3WrVvTvXv3eu2jh9eLiJQAPbxeRERSUiIQESlxSgQiIiWu6NoIzGwVsDTfcaTQBfg430Gkofgap9Djg8KPUfE1TmPi6+nuSW/EKrpEUMjMrDJVY0whUHyNU+jxQeHHqPgaJ1vxqWpIRKTEKRGIiJQ4JYKmNTnfAdRB8TVOoccHhR+j4mucrMSnNgIRkRKnEoGISIlTIhARKXFKBPVkZgeZ2XNmNt/Mqs3s20m2GWZm6+OexXxDjmNcYmZvRJ+9x8BMFtwRPUt6npkNzmFsfePOyxwz22BmVyZsk/PzZ2b3mtlHZlYVt6yTmT1lZguj931T7HtBtM1CM7sgR7HdYmYLon+/P5lZxxT7pv0uZDnGiWb2Qdy/42kp9k37bPMsxjctLrYlZjYnxb5ZPYeprik5/f65u171eAHdgMHRdHvgbaB/wjbDgL/kMcYlQJc0608DngAMOAZ4JU9xlgErCDe65PX8AScCg4GquGU/AyZE0xOAm5Ps1wl4J3rfN5reNwexfQloGU3fnCy2TL4LWY5xInB1Bt+BxcDBwF7A3MT/T9mKL2H9/wI35OMcprqm5PL7pxJBPbn7cnefHU1vJDxDIdkjOAvZSOB3Hvwb6JjwbIhcORlY7O55v1Pc3V8gDIUebyS7npr3APCfSXb9MvCUu69x97WEJ+0Nz3Zs7v53d6+JZv9NePBT3qQ4f5k4Cljk7u+4+zZgKuG8N6l08ZmZAecBv2/qz81EmmtKzr5/SgSNYGa9gEHAK0lWH2tmc83sCTM7PLeR4cDfzew1M7s4yfpMnyedbeeT+j9fPs9fzGfcfXk0vQL4TJJtCuFcjiWU8JKp67uQbZdH1Vf3pqjaKITzdwKw0t0Xplifs3OYcE3J2fdPiaCBzKwd8BhwpbtvSFg9m1DdMQD4BTA9x+Ed7+6DgVOBy8zsxBx/fp0sPLVuBPCHJKvzff724KEcXnB9rc3sesKDnaak2CSf34VfA4cAA4HlhOqXQjSK9KWBnJzDdNeUbH//lAgawMxaEf7Bprj7HxPXu/sGd/8kmp4JtDKzLrmKz90/iN4/Av5EKH7Hq/N50jlwKjDb3Vcmrsj3+YuzMlZlFr1/lGSbvJ1LMxsDnAGMji4Ue8jgu5A17r7S3Xe4+07g7hSfndfvopm1BM4CpqXaJhfnMMU1JWffPyWCeorqE+8B3nT3n6fYZv9oO8zsKMJ5Xp2j+NqaWfvYNKFRsSphsxnANyw4BlgfVwTNlZS/wvJ5/hLMAGK9MC4A/pxkmyeBL5nZvlHVx5eiZVllZsOBa4ER7r4pxTaZfBeyGWN8u9OZKT67zmebZ9kpwAJ3X5ZsZS7OYZprSu6+f9lqCW+uL+B4QhFtHjAnep0GjAPGRdtcDlQTekD8Gxiaw/gOjj53bhTD9dHy+PgMuJPQW+MNoCLH57At4cLeIW5ZXs8fISktB7YT6lkvAjoDzwALgaeBTtG2FcBv4/YdCyyKXhfmKLZFhLrh2HfwrmjbA4CZ6b4LOTx/D0bfr3mEi1q3xBij+dMIPWUWZyvGZPFFy++Pfe/its3pOUxzTcnZ909DTIiIlDhVDYmIlDglAhGREqdEICJS4pQIRERKnBKBiEiJUyIQiZjZDtt9ZNQmGwnTzHrFj3wpUkha5jsAkQKy2d0H5jsIkVxTiUCkDtF49D+LxqR/1cw+Gy3vZWbPRoOqPWNmPaLln7HwjIC50WtodKgyM7s7GnP+72bWJtr+imgs+nlmNjVPf6aUMCUCkV3aJFQNfSVu3Xp3PwL4JXB7tOwXwAPufiRh0Lc7ouV3AP/wMGjeYMIdqQB9gDvd/XBgHXB2tHwCMCg6zrjs/GkiqenOYpGImX3i7u2SLF8CfMHd34kGB1vh7p3N7GPCsAnbo+XL3b2Lma0Curv71rhj9CKMG98nmv8O0Mrdf2RmfwM+IYyyOt2jAfdEckUlApHMeIrp+tgaN72DXW10pxPGfhoMzIpGxBTJGSUCkcx8Je795Wj6JcJomQCjgRej6WeA8QBmVmZmHVId1MxaAAe5+3PAd4AOwB6lEpFs0i8PkV3a2O4PMP+bu8e6kO5rZvMIv+pHRcu+BdxnZtcAq4ALo+XfBiab2UWEX/7jCSNfJlMGPBQlCwPucPd1TfT3iGREbQQidYjaCCrc/eN8xyKSDaoaEhEpcSoRiIiUOJUIRERKnBKBiEiJUyIQESlxSgQiIiVOiUBEpMT9f4Vf6tR/b7RBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # 그림 초기화\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03611e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da146c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다.\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6cc84d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01631728,  0.0355123 , -0.01784502, -0.04364004,  0.07624035,\n",
       "        0.0441875 ,  0.02565757,  0.06309228,  0.04683638, -0.05271655,\n",
       "        0.02481499,  0.0455235 , -0.07764395,  0.00908102, -0.07027322,\n",
       "       -0.03542773], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "800d1f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('raw', 0.8804479241371155),\n",
       " ('reveal', 0.8623505234718323),\n",
       " ('soles', 0.8604695796966553),\n",
       " ('fun', 0.8603529334068298),\n",
       " ('48', 0.8576575517654419),\n",
       " ('novak', 0.8524704575538635),\n",
       " ('well', 0.8474664688110352),\n",
       " ('style', 0.8375077247619629),\n",
       " ('loved', 0.822443425655365),\n",
       " ('pacino', 0.8158224821090698)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a51b33d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "vector = word2vec['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "433a091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('Ilove', 0.5702950954437256),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의하세요.\n",
    "word2vec.similar_by_word('love')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18e5b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4afe35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "590858d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 86ms/step - loss: 0.6985 - accuracy: 0.5255 - val_loss: 0.6771 - val_accuracy: 0.5804\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.6471 - accuracy: 0.6418 - val_loss: 0.6331 - val_accuracy: 0.6310\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.5346 - accuracy: 0.7611 - val_loss: 0.4750 - val_accuracy: 0.7832\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.3646 - accuracy: 0.8557 - val_loss: 0.3415 - val_accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.2601 - accuracy: 0.8997 - val_loss: 0.3139 - val_accuracy: 0.8682\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1913 - accuracy: 0.9341 - val_loss: 0.3075 - val_accuracy: 0.8733\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1370 - accuracy: 0.9601 - val_loss: 0.3011 - val_accuracy: 0.8772\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1050 - accuracy: 0.9725 - val_loss: 0.3127 - val_accuracy: 0.8766\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0706 - accuracy: 0.9847 - val_loss: 0.3656 - val_accuracy: 0.8644\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0533 - accuracy: 0.9916 - val_loss: 0.3410 - val_accuracy: 0.8727\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0335 - accuracy: 0.9973 - val_loss: 0.3580 - val_accuracy: 0.8719\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0227 - accuracy: 0.9986 - val_loss: 0.3697 - val_accuracy: 0.8731\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0159 - accuracy: 0.9994 - val_loss: 0.3870 - val_accuracy: 0.8731\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0116 - accuracy: 0.9996 - val_loss: 0.4016 - val_accuracy: 0.8720\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 0.4156 - val_accuracy: 0.8715\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0067 - accuracy: 0.9998 - val_loss: 0.4321 - val_accuracy: 0.8713\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 74ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.4420 - val_accuracy: 0.8715\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0045 - accuracy: 0.9999 - val_loss: 0.4528 - val_accuracy: 0.8710\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.4631 - val_accuracy: 0.8709\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.4716 - val_accuracy: 0.8707\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a91fcd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5023 - accuracy: 0.8620\n",
      "[0.5023434162139893, 0.8619599938392639]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9fc01e",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac235b9",
   "metadata": {},
   "source": [
    "### Word2Vec를 이용하여 Pre-Trained된 Word2Vec Embedding 모델을 사용하였지만 이 모델에서도 유일하게 LSTM 만 85%를 넘을 수 있었다.\n",
    "### 아직 머신러닝이나 딥러닝의 모델을 설계하는 정확한 이해 없이 정확도를 올리려고 하니까 너무 어려운 것 같다.\n",
    "### 물론 아직 배우기 시작하는 단계라서 어쩔 수 없다고 생각은 하지만 모델 설계에 대한 공부도 따로 해야겠다.\n",
    "### 일단 이미지 인식과 자연어 처리 둘 다 경험은 해봤으니 앞으로 어떤 분야에 집중을 할지 고민해봐야겠다.\n",
    "### 이미지 인식를 활용하여 보다 많은 이미지를 변환해보고 싶다는 욕심이 생겼고, 요즘 핫한 Chatgpt도 자연어 처리를 이용한 AI여서 관심을 놓을수가 없었다.\n",
    "### 점점 학습과정들이 어려워 지는 것같아 걱정이 되는 한편 더욱더 열심히 노력해야 겠다는 생각이 들었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
