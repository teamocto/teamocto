{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e420c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ab1615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "data = pd.read_csv('ChatBotData.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3638f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19717752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 행의 크기가 50 열의 크기가 512인 행렬 = 문장의 최대길이가 50이고, 워드 임베딩 차원수가 512라고 볼 수 있다.\n",
    "sample_pos_encoding = PositionalEncoding(50, 512)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1878260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  \"\"\"어텐션 가중치를 계산. \"\"\"\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # scale matmul_qk\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # add the mask to zero out padding tokens\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax is normalized on the last axis (seq_len_k)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afd76ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # linear layers\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다.\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다.\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # final linear layer\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d1c35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e23faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c71eae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e3504b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cecd53da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[1. 1. 1. 1. 1.]\n",
      "   [1. 0. 1. 1. 1.]\n",
      "   [1. 0. 0. 1. 1.]\n",
      "   [1. 0. 0. 0. 1.]\n",
      "   [1. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 0으로 패딩마스킹이 된 경우도 룩어헤드 마스킹처리 됨\n",
    "print(create_look_ahead_mask(tf.constant([[0, 5, 1, 5, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cace59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "\t# 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc48e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "\t# 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf2534f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce569bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "\t# 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "\t# 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "\t# 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "\t# Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2259b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'cornell_movie_dialogs.zip',\n",
    "    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd82b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a03c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규 표현식(Regular Expression)을 사용하여 구두점(punctuation)을 제거하여 단어를 토크나이징(tokenizing)하는 일에 방해가 되지 않도록 정제\n",
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d1ecc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "  id2line = {}\n",
    "  with open(path_to_movie_lines, errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    id2line[parts[0]] = parts[4]\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(path_to_movie_conversations, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(conversation) - 1):\n",
    "\t\t\t# 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "      if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f337576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 50000\n",
      "전체 샘플 수 : 50000\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6beae1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: she s not a . . .\n",
      "전처리 후의 22번째 답변 샘플: lesbian ? no . i found a picture of jared leto in one of her drawers , so i m pretty sure she s not harboring same sex tendencies .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[21]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2b2bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99071cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "019e6d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8331]\n",
      "END_TOKEN의 번호 : [8332]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abdf58c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8333\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f841fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [60, 8, 37, 8172, 49]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [7824, 1223, 19, 61, 2, 4, 336, 10, 1595, 14, 1104, 698, 3263, 263, 16, 71, 14, 107, 2133, 900, 3, 59, 4, 23, 355, 204, 60, 8, 37, 885, 2289, 8107, 344, 1001, 5179, 4214, 342, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fc1ae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb8e4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30d2104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8333\n",
      "필터링 후의 질문 샘플 개수: 44095\n",
      "필터링 후의 답변 샘플 개수: 44095\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f405e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67d135d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\t# 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ee504c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3187456     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3714816     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8333)   2141581     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,043,853\n",
      "Trainable params: 9,043,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c004050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수 정의\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e8bb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법\n",
    "# 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19f97449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a54ad74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "421fb062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "689/689 [==============================] - 45s 56ms/step - loss: 2.1129 - accuracy: 0.0423\n",
      "Epoch 2/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.4999 - accuracy: 0.0789\n",
      "Epoch 3/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.3932 - accuracy: 0.0860\n",
      "Epoch 4/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.3332 - accuracy: 0.0905\n",
      "Epoch 5/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.2808 - accuracy: 0.0946\n",
      "Epoch 6/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.2340 - accuracy: 0.0982\n",
      "Epoch 7/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.1788 - accuracy: 0.1024\n",
      "Epoch 8/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.1178 - accuracy: 0.1077\n",
      "Epoch 9/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.0587 - accuracy: 0.1137\n",
      "Epoch 10/10\n",
      "689/689 [==============================] - 38s 55ms/step - loss: 1.0057 - accuracy: 0.1195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1728573130>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b68f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75fc3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6fcfefd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Where have you been?\n",
      "출력 : i m going to see you .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m going to see you .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('Where have you been?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89aa1a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : It's a trap\n",
      "출력 : i don t know . i m not going to be a doctor .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i don t know . i m not going to be a doctor .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"It's a trap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "907dd414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 10000\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46942284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규 표현식(Regular Expression)을 사용하여 구두점(punctuation)을 제거하여 단어를 토크나이징(tokenizing)하는 일에 방해가 되지 않도록 정제\n",
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Zㄱ-ㅣ가-힣0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17269853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations():\n",
    "  id2line = {}\n",
    "  with open(path_to_movie_lines, errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    id2line[parts[0]] = parts[4]\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(path_to_movie_conversations, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(conversation) - 1):\n",
    "\t\t\t# 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "      if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcfa58b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "questions, answers = [], []\n",
    "for q, a in zip(data['Q'], data['A']):\n",
    "    questions.append(preprocess_sentence(q))\n",
    "    answers.append(preprocess_sentence(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b48ebde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 22번째 질문 샘플: SNS보면 나만 빼고 다 행복해보여\n",
      "전처리 후의 22번째 답변 샘플: 자랑하는 자리니까요 .\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[10]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0e7317b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"ChatBotData\")\n",
    "\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab10cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07fbecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [4041]\n",
      "END_TOKEN의 번호 : [4042]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6390520a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 10번째 질문 샘플: [3868, 3863, 3868, 676, 307, 736, 10, 54, 547, 941]\n",
      "정수 인코딩 후의 10번째 답변 샘플: [67, 2639, 50, 1154, 372, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 10번째 질문 샘플: {}'.format(tokenizer.encode(questions[10])))\n",
    "print('정수 인코딩 후의 10번째 답변 샘플: {}'.format(tokenizer.encode(answers[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "021c9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 12\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d2ff462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "da37f7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 4041\n",
      "필터링 후의 질문 샘플 개수: 9607\n",
      "필터링 후의 답변 샘플 개수: 9607\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(tokenizer.vocab_size))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d9515faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22d8ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "\t# 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "062b5b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3187456     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3714816     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8333)   2141581     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,043,853\n",
      "Trainable params: 9,043,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6954c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 손실 함수 정의\n",
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f5c17f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법\n",
    "# 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e03afd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e3e72b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 10s 31ms/step - loss: 5.3553 - accuracy: 0.0934\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 4.4101 - accuracy: 0.1732\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 3.6519 - accuracy: 0.1782\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 3.3137 - accuracy: 0.1891\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 3.1077 - accuracy: 0.2009\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 2.9043 - accuracy: 0.2156\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 2.6914 - accuracy: 0.2360\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 2.4701 - accuracy: 0.2601\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 2.2463 - accuracy: 0.2843\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 2.0168 - accuracy: 0.3101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16ac0ceb80>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f511ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0a3bbf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수\n",
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a7640ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : SNS 맞팔 왜 안하지ㅠㅠ\n",
      "출력 : 좋은 사람 만날 수 있을 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'좋은 사람 만날 수 있을 거예요 .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('SNS 맞팔 왜 안하지ㅠㅠ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f148059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 가상화폐\n",
      "출력 : 저도 듣고 싶네요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 듣고 싶네요 .'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('가상화폐')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8977f3e4",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6d9f1",
   "metadata": {},
   "source": [
    "### 아직 완벽하지 않고 많은 보완이 필요해 보인다.\n",
    "### GPT에 비교할 수 없을 정도로 허접하다.\n",
    "### 하지만 하나둘씩 보완해 나가다 보면 멋진 프로그램으로 거듭날 수 있을듯...\n",
    "### 전처리 과정부터 문장을 여러모로 시도해보고 여러 모듈들을 접목하여 시도해보는 시간이었다.\n",
    "### 러닝레이트에 대한 정보를 더 알게된 시간이었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
